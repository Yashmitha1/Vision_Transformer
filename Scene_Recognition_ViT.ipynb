{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75996,"status":"ok","timestamp":1721993172722,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"XM1uq0HD5sa1","outputId":"a0c382d3-e2c3-45da-8533-bbbfbcbf76bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting timm\n","  Downloading timm-1.0.7-py3-none-any.whl.metadata (47 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.5)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 timm-1.0.7\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32687,"status":"ok","timestamp":1721992995999,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"Qft9_D1Jrzvm","outputId":"915751c8-8675-4528-d12a-cdfb490b203e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# importing dataset folder\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1721992995999,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"hYULCCf2sBp2","outputId":"804fc063-6e8a-4fe0-8057-260741144d05"},"outputs":[{"data":{"text/plain":["['Classroom',\n"," 'SWOT Analysis.gdoc',\n"," 'swot analysis (sunshine buddy).pdf',\n"," 'Guitar actual (2).par',\n"," 'guitar CAD (2).png',\n"," 'guitar CAD (1).png',\n"," 'guitar CAD.png',\n"," 'Guitar actual (1).par',\n"," 'Guitar actual.par',\n"," 'Untitled form.gform',\n"," 'IMG_3400.jpg',\n"," 'Complex_4.gdoc',\n"," 'Buddy report.docx',\n"," 'WhatsApp Image 2023-01-08 at 12.50.19.jpeg',\n"," 'ES22BTECH11014_Assig1.pdf',\n"," 'Yashmitha Sunshine',\n"," 'IMG-20230310-WA0021.jpg',\n"," 'IMG-20230320-WA0028.jpg',\n"," 'ID card Mar 21, 2023_1.jpg',\n"," '16793907569285353538747914663683.jpg',\n"," 'IMG_20230321_150026.jpg',\n"," 'SlotA-students.gsheet',\n"," 'MA1140_ assignment_1-ES22BTECH11014.pdf',\n"," 'IMG-20230408-WA0079.jpg',\n"," 'A1_ES22BTECH11014_2.par',\n"," 'A1_ES22BTECH11014_3.par',\n"," 'A1_ES22BTECH11014_1.par',\n"," 'Milan 2022-23',\n"," 'Screenshot_2023-08-15-17-38-38-54_49b96b5fbae0d12a18edc4a3afe0dfd9.jpg',\n"," 'Screenshot_2023-08-15-19-42-10-71_49b96b5fbae0d12a18edc4a3afe0dfd9.jpg',\n"," 'IMG20230918203856.jpg',\n"," 'IMG20230918204056.jpg',\n"," 'IMG20230918204305.jpg',\n"," 'Folk theatre',\n"," 'ACM.pdf',\n"," 'YASHMITHA_GOGINENI_Marksheet_2023 (2).jpg',\n"," 'YASHMITHA_GOGINENI_Marksheet_2023 (1).jpg',\n"," 'YASHMITHA_GOGINENI_Marksheet_2023.jpg',\n"," 'YASHMITHA_GOGINENI_Marksheet_2022 (1).jpg',\n"," 'YASHMITHA_GOGINENI_Marksheet_2022.jpg',\n"," 'YASHMITHA_GOGINENI_Marksheet_2020.jpg',\n"," 'YASHMITHA_GOGINENI_Photo.jpg',\n"," 'YASHMITHA_GOGINENI_Aadhar.jpg',\n"," 'YASHMITHA_GOGINENI_SOPLetter (3).pdf',\n"," 'YASHMITHA_GOGINENI_SOPLetter (2).pdf',\n"," 'YASHMITHA_GOGINENI_SOPLetter (1).pdf',\n"," 'YASHMITHA_GOGINENI_SOPLetter.pdf',\n"," 'Assgn_Power_Series.gdoc',\n"," 'Colab Notebooks',\n"," '2023-11-22 01-33-15.mp4',\n"," '2023-11-22 13-57-23.mp4',\n"," 'Weekly time sheet.gsheet',\n"," 'Schedule.gsheet',\n"," 'Screenshot 2023-12-03 162416.png',\n"," 'sem1grades.png',\n"," 'sem2grades.png',\n"," 'sem3grades.png',\n"," 'sem1gradesERP.png',\n"," 'sem2gradesERP.png',\n"," 'Quarterly Report(2023-24)-Sunshine.pdf',\n"," 'Copy of IMG_8408.JPG',\n"," \"Diesta'24 Music Room Slots.gsheet\",\n"," \"Stranger Bands '24.gform\",\n"," 'Untitled document (1).gdoc',\n"," 'JST_application.gdoc',\n"," 'Letter of Guarantee_NAIK AVANEESH.pdf',\n"," 'Yashmitha_G (2).pdf',\n"," 'Quarterly Report(2023-24)-Sunshine.gdoc',\n"," 'Quarterly Report(2023-24)-Sunshine.docx',\n"," 'Untitled document.gdoc',\n"," 'Yashmitha ',\n"," '03_List of Invitees_IIT Hyderabad_Indian University Student Invitation Program 2024.xlsx',\n"," 'ES22BTECH11014_Yashmitha_Scriptwriting.pdf',\n"," '12th marksheet_compressed.pdf',\n"," 'Yashmitha_10th certificate_compressed.pdf',\n"," 'score card.png',\n"," 'Yashmi.jpeg',\n"," 'Hostel Rep Approval.png',\n"," 'Inbound Buddy and Overall Head, IR Cell POR approval.png',\n"," 'Vibes Core approval.png',\n"," 'UG_Buddy Approval.png',\n"," 'UG_Mentor Approval.png',\n"," 'Top 1.5 % KVS AISSCE 2022 Proof.jpeg',\n"," 'School Topper Proof.jpeg',\n"," 'DigiFab TA Proof.png',\n"," 'YASHMITHA_GOGINENI_Marksheet_2024.pdf',\n"," 'Yashmitha_Gogineni_Passport.jpeg',\n"," 'Yashmitha_Gogineni_Aadhar.jpeg',\n"," 'Yashmitha_Gogineni_SOPLetter.pdf',\n"," 'YASHMITHA_GOGINENI_Marksheet_2024.jpg',\n"," 'Yashmitha_Gogineni_Photo.jpeg',\n"," 'archive (2)',\n"," 'indoorCVPR_09']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.listdir('/content/drive/My Drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvrMzpeQsTNg"},"outputs":[],"source":["os.chdir('/content/drive/My Drive/indoorCVPR_09')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1721992997333,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"sb-E7b8AzkDd","outputId":"25f7f517-3885-4ddd-945e-27eee757ff42"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/indoorCVPR_09\n"]}],"source":["cwd = os.getcwd()\n","print(cwd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1721992997333,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"POMMMTDCsaG-","outputId":"3493bbdc-f875-40cc-c490-7b4dd8e83fb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Images']\n"]}],"source":["print(os.listdir())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSenwdhcscy6"},"outputs":[],"source":["#import necessary libraries\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torchvision.datasets  import ImageFolder\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","import pandas as pd\n","import os\n","\n","#define tranformations\n","transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","#create the ImageFolder Dataset\n","dataset = ImageFolder(root='/content/drive/MyDrive/indoorCVPR_09/Images', transform = transform)\n","classes = dataset.classes\n","\n","#get all class labels\n","targets =[sample[1] for sample in dataset.samples]\n","\n","#first stratified split to create a train+val and test sets\n","train_val_indices, test_indices = train_test_split(\n","    np.arange(len(targets)),\n","    test_size = 0.2,\n","    stratify = targets,\n","    random_state = 42\n",")\n","\n","#get class labels for the train+val set\n","train_val_targets = [targets[i] for i in train_val_indices]\n","\n","#second stratified split to create train and val sets\n","train_indices, val_indices = train_test_split(\n","    train_val_indices,\n","    test_size = 0.25, #0.25*0.8 = 0.2 i.e. 20% of total dataset\n","    stratify = train_val_targets,\n","    random_state = 42\n",")\n","\n","# create subset datasets\n","train_dataset = Subset(dataset, train_indices)\n","val_dataset = Subset(dataset, val_indices)\n","test_dataset = Subset(dataset, test_indices)\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b47e8f2395d94db5bda0252a4128374e","3faec1a9e2ca4c9bb3d87f5fce256c65","ada9188b4c3b42c2a8b92d898b4b4502","4e815ebc170143a791244cb677a7ae80","278ffba7141e453cb2fdc7cf70188739","7ead9b2b53414f24a1085982a18cf568","b8fbbbd0e51543c9b2c2c77c9728b8c5","a1fabac7caab4c7d9d2724f6cdfbd593","96446dddd8474883b2366a9c1c663d1d","a0f0fdd9e0db474d9c1bade7bbfecb07","a54f55b3a5144f32833a077085e1c839"]},"executionInfo":{"elapsed":10771,"status":"ok","timestamp":1721993183474,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"P7JC-4Mb5Z8B","outputId":"c328eafc-6e83-41f7-8be1-3af94a158fc7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b47e8f2395d94db5bda0252a4128374e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["VisionTransformer(\n","  (patch_embed): PatchEmbed(\n","    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","    (norm): Identity()\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (patch_drop): Identity()\n","  (norm_pre): Identity()\n","  (blocks): Sequential(\n","    (0): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (1): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (2): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (3): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (4): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (5): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (6): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (7): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (8): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (9): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (10): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","    (11): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls1): Identity()\n","      (drop_path1): Identity()\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate='none')\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (norm): Identity()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","      (ls2): Identity()\n","      (drop_path2): Identity()\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (fc_norm): Identity()\n","  (head_drop): Dropout(p=0.0, inplace=False)\n","  (head): Linear(in_features=768, out_features=67, bias=True)\n",")\n"]}],"source":["import timm\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#load a pretrained ViT model\n","#model = timm.create_model('resnet50', pretrained = True)\n","model = timm.create_model('vit_base_patch16_224', pretrained=True)\n","#model.fc = nn.Linear(model.fc.in_features, 66)\n","outputs_attrs = 67\n","num_inputs = model.head.in_features\n","last_layer = nn.Linear(num_inputs, outputs_attrs)\n","model.head = last_layer\n","# Freeze all layers except the head\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze the head layer\n","for param in model.head.parameters():\n","    param.requires_grad = True\n","\n","#move the model to appropriate device\n","model = model.to(device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qu5df4QJ7pr1"},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","\n","#defining loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","# Define the learning rate scheduler\n","scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vyQAuqM2773v"},"outputs":[],"source":["#training loop\n","def main():\n","  num_epochs = 10\n","  for epoch in range(num_epochs):\n","      model.train()\n","      running_loss = 0.0\n","      for i, (images, labels) in enumerate(train_loader):\n","          images, labels = images.to(device), labels.to(device)\n","\n","          #forward pass\n","          output = model(images)\n","          loss = criterion(output, labels)\n","\n","          #Backward pass and optimisation\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss+=loss.item()\n","          if (i+1) % 10 == 0:  # Print every 10 batches\n","              print(f'Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","      # Validation\n","      model.eval()\n","      val_loss = 0.0\n","      correct = 0\n","      total = 0\n","      with torch.no_grad():\n","          for images, labels in val_loader:\n","              images, labels = images.to(device), labels.to(device)\n","              outputs = model(images)\n","              loss = criterion(outputs, labels)\n","              val_loss += loss.item()\n","              _, predicted = torch.max(outputs.data, 1)\n","              total += labels.size(0)\n","              correct += (predicted == labels).sum().item()\n","\n","      print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n","    # Test\n","  model.eval()\n","  test_loss = 0.0\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          loss = criterion(outputs, labels)\n","          test_loss += loss.item()\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  print(f'Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {100 * correct / total:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"99ImBGe0jfED","outputId":"30d8dfef-84dc-4601-b2e1-66954fa431ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch [10/293], Loss: 4.3177\n","Batch [20/293], Loss: 3.9674\n","Batch [30/293], Loss: 3.7886\n","Batch [40/293], Loss: 4.0049\n","Batch [50/293], Loss: 3.4791\n","Batch [60/293], Loss: 3.4600\n","Batch [70/293], Loss: 3.4369\n","Batch [80/293], Loss: 3.0931\n","Batch [90/293], Loss: 3.0729\n","Batch [100/293], Loss: 2.8908\n","Batch [110/293], Loss: 2.5537\n","Batch [120/293], Loss: 2.5110\n","Batch [130/293], Loss: 2.1033\n","Batch [140/293], Loss: 2.1320\n"]}],"source":["main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17268,"status":"ok","timestamp":1721993058233,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"TFShAwB8uhIn","outputId":"56111c32-bd2e-48c4-f013-49fa8468b1ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gradio\n","  Downloading gradio-4.39.0-py3-none-any.whl.metadata (15 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==1.1.1 (from gradio)\n","  Downloading gradio_client-1.1.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.1->gradio) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.1->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n","  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n","Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n","Collecting email_validator>=2.0.0 (from fastapi->gradio)\n","  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n","  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-4.39.0-py3-none-any.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.1.1-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=691d1ad8213d6ced81959654ef2ac8b5e52728cb86fa354822d3767ee081dd0a\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uvloop, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n","Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.39.0 gradio-client-1.1.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.6 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.5 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"]}],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":7332,"status":"error","timestamp":1721993065556,"user":{"displayName":"Gogineni Yashmitha","userId":"17682059586609901076"},"user_tz":-330},"id":"xtWpZp45w5bN","outputId":"193c35bb-1a4a-4934-99fe-ddc21d8392b8"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b58d0c2a10fa>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load your pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the transformation for the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["import gradio as gr\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","\n","# Load your pre-trained model\n","\n","model.eval()\n","\n","# Define the transformation for the input image\n","transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","\n","# Function to make predictions\n","def predict(image):\n","    # Transform the input image\n","    image = transform(image).unsqueeze(0)  # Add batch dimension\n","\n","    # Send the image to the model and get predictions\n","    with torch.no_grad():\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs, 1)\n","        predicted_class = classes[predicted.item()]\n","\n","    return predicted_class\n","\n","# Define the Gradio interface\n","iface = gr.Interface(\n","    fn=predict,\n","    inputs=gr.inputs.Image(shape=(224, 224)),\n","    outputs=\"text\",\n","    title=\"Image Classification\",\n","    description=\"Upload an image to get the classification result.\"\n",")\n","\n","# Launch the Gradio interface\n","iface.launch()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMFKGQiNNYYtJP24Yuo2V8G"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"278ffba7141e453cb2fdc7cf70188739":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3faec1a9e2ca4c9bb3d87f5fce256c65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ead9b2b53414f24a1085982a18cf568","placeholder":"​","style":"IPY_MODEL_b8fbbbd0e51543c9b2c2c77c9728b8c5","value":"model.safetensors: 100%"}},"4e815ebc170143a791244cb677a7ae80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f0fdd9e0db474d9c1bade7bbfecb07","placeholder":"​","style":"IPY_MODEL_a54f55b3a5144f32833a077085e1c839","value":" 346M/346M [00:04&lt;00:00, 103MB/s]"}},"7ead9b2b53414f24a1085982a18cf568":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96446dddd8474883b2366a9c1c663d1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0f0fdd9e0db474d9c1bade7bbfecb07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fabac7caab4c7d9d2724f6cdfbd593":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a54f55b3a5144f32833a077085e1c839":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ada9188b4c3b42c2a8b92d898b4b4502":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1fabac7caab4c7d9d2724f6cdfbd593","max":346284714,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96446dddd8474883b2366a9c1c663d1d","value":346284714}},"b47e8f2395d94db5bda0252a4128374e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3faec1a9e2ca4c9bb3d87f5fce256c65","IPY_MODEL_ada9188b4c3b42c2a8b92d898b4b4502","IPY_MODEL_4e815ebc170143a791244cb677a7ae80"],"layout":"IPY_MODEL_278ffba7141e453cb2fdc7cf70188739"}},"b8fbbbd0e51543c9b2c2c77c9728b8c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}